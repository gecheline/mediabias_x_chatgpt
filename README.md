# Media Bias x ChatGPT
A ML model and app for detecting bias in media and AI generated content on a set of topics. 

This repository explores approached to classification based on topic, bias and political bias in sentences sourced from various media outlets, using the OpenAI ADA embeddings. It additionally explores the political bias of content generated by ChatGPT with the trained model on human-labeled data.

## Dependencies
The code in this repository utilizes the following packages:
- numpy
- pandas
- plotly
- scikit-learn
- umap-learn
- openai
- tiktoken

The accompanying web app additionally depends on streamlit, which was used to build it.

## Data and Modeling
The data used for training the machine learning models was obtained from [the BABE dataset on Kaggle](https://www.kaggle.com/datasets/timospinde/babe-media-bias-annotations-by-experts). I used the largest dataset of sentences labeled by human experts (SG2). Approaches to topic, bias and outlet bias classification were explored with sklearn and we found that:
- a neigbors (distance) based topic works best for topic due to the nature of ADA embeddings
- LogisticRegression was the best classifier for bias, closely followed by RandomForest and MLP classifiers
- an MLP classifier performed best for the political (outlet) bias prediction of the sentences.
Additionally, all model hyperparameters were tuned using a grid search with cross validation method with 5 folds. Due to the unbalanced nature of the dataset, the F1-weighted score was used as the main metric to assess model performance.

## Repository structure
The notebooks/ directory contains all steps I took in the process of data exploration and model selection / hyper parameter tuning. 

The notebooks/ETL_exploration.ipynb notebook outlines the data exploration and embedding approach.

The notebooks/MLP_exploration.ipynb notebook outlines the model selection and hyperparameter tuning for all three classifiers.

The final model is implemented and trained in notebooks/ETL_MLP_pipeline.ipynb file.

All models and data used can be found in the data/ and models/ directories.

The top-level .py files in the repository contain all the files needed to run the streamlit app and contain both code for data exploraiton and modeling, as well as detailed overview of the process with interactive visualizations.

## ChatGPT bias

The main question I tried to answer in the final deliverable of this project is whether content generated with ChatGPT is perceived as politically biased with respect to content generally reported by media outlets. For this purpose, I prompted ChatGPT to produce several sentences on a small set of topics present in the training data. All content generated by ChatGPT was classified as non-biased, but in terms of political bias a left-leaning classification showed to be more prevalent. The accompanying interactive app can be used to test any content with a valid OpenAI API key! 

## Running the app locally
Clone this repo and install the dependencies with
```
pip install -r requirements.txt
```
Run the app with
```
streamlit run app.py
```

## Live App
The full process is documented and live in a [streamlit app](https://gecheline-mediabias-x-chatgpt-app-b6uock.streamlit.app/). Some of the interactive functionalities may run slow due to all the preprocessing and communication with the OpenAI API, so be patient!
